Blob Storage and S3

Earlier when people upload any files they uploaded it to server and were stored on the hard disk attached to it . 

Getting a file was simple make an API call the handler reads the file and returns it to the user

This is precisely how / static folders/ routed worked


When a user uploads the file -> accept it on HTTP POST 
a.txt                           - create absolute path using folder mapped to                             '/static' , it stores in /home/user/static/a.txt
                            -> store the file at above location 

When user requests '/static/a.txt' -> get the path from URL -> read the file and return it to the user


This worked well for quite some time but won't work with multiple servers because each server will have its own disk.


Hence we need an infinitely scalable network attached storage/ file system .(this is S3/ blob storage)

Any file that needs to be accessible by any server is stored at a places accessible by all 


On S3 we have: 
buckets: (namespace) eg: insta-images, my-bucket( any unique name)
keys: path of the file within bucket 

S3:// insta-images/user123/123.png
    bucket          key 



We can seamlessly , create the file, replace the file, delete the file, read entire file or segment of it . 



Advantages: - cheap, durable storage, can store literally any file , scalabel and available, integration with a lot of AWS and Big Data services 
(images, video, audio, text, DB backup , DB CSV exports etc)

Disadvantages: - reads on S3 are slow , so if we want quick reads we should not use S3 (SSD and HDD attached to instances or better)
- not a full fledged file system 

We should use S3 when we want to store 'blob' that is centrally accessible 
- Database backups - logs archival  - static website hosting - infrequently accessed data dumping ground 
- big data storage 